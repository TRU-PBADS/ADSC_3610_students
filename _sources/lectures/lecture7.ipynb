{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 7: Aggregation operations in MongoDB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning objectives\n",
    "\n",
    "By the end of this lecture, students should understand:\n",
    "- Define aggregation and the components of an aggregation pipeline.\n",
    "- Build an aggregation pipeline that uses the `$match` and `$group` stages.\n",
    "- Build an aggregation pipeline that uses the `$sort` and `$project` stages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to MongoDB database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient # import mongo client to connect\n",
    "import json # import json to load credentials\n",
    "import urllib.parse\n",
    "\n",
    "# load credentials from json file\n",
    "with open('credentials_mongodb.json') as f:\n",
    "    login = json.load(f)\n",
    "\n",
    "# assign credentials to variables\n",
    "username = login['username']\n",
    "password = urllib.parse.quote(login['password'])\n",
    "host = login['host']\n",
    "url = \"mongodb+srv://{}:{}@{}/?retryWrites=true&w=majority\".format(username, password, host)\n",
    "\n",
    "# connect to the database\n",
    "client = MongoClient(url)\n",
    "\n",
    "# drop database books and students if they exist\n",
    "client.drop_database('library')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create database and collection\n",
    "db = client[\"library\"]\n",
    "collection = db[\"books\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InsertManyResult([ObjectId('66eb9baaddbe7989b91b279a'), ObjectId('66eb9baaddbe7989b91b279b'), ObjectId('66eb9baaddbe7989b91b279c'), ObjectId('66eb9baaddbe7989b91b279d'), ObjectId('66eb9baaddbe7989b91b279e'), ObjectId('66eb9baaddbe7989b91b279f'), ObjectId('66eb9baaddbe7989b91b27a0'), ObjectId('66eb9baaddbe7989b91b27a1'), ObjectId('66eb9baaddbe7989b91b27a2'), ObjectId('66eb9baaddbe7989b91b27a3'), ObjectId('66eb9baaddbe7989b91b27a4'), ObjectId('66eb9baaddbe7989b91b27a5'), ObjectId('66eb9baaddbe7989b91b27a6')], acknowledged=True)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample book data\n",
    "sample_books = [\n",
    "    {\"title\": \"To Kill a Mockingbird\", \"author\": \"Harper Lee\", \"pages\": 281, \"year\": 1960},\n",
    "    {\"title\": \"Go Set a Watchman\", \"author\": \"Harper Lee\", \"pages\": 278, \"year\": 2015},\n",
    "    {\"title\": \"Mockingbird Songs: My Friendship with Harper Lee\", \"author\": \"Harper Lee\", \"pages\": 288, \"year\": 2017},\n",
    "    \n",
    "    {\"title\": \"1984\", \"author\": \"George Orwell\", \"pages\": 328, \"year\": 1949},\n",
    "    {\"title\": \"Animal Farm\", \"author\": \"George Orwell\", \"pages\": 112, \"year\": 1945},\n",
    "    \n",
    "    {\"title\": \"Pride and Prejudice\", \"author\": \"Jane Austen\", \"pages\": 279, \"year\": 1813},\n",
    "    {\"title\": \"Sense and Sensibility\", \"author\": \"Jane Austen\", \"pages\": 226, \"year\": 1811},\n",
    "    {\"title\": \"Emma\", \"author\": \"Jane Austen\", \"pages\": 474, \"year\": 1815},\n",
    "    \n",
    "    {\"title\": \"The Great Gatsby\", \"author\": \"F. Scott Fitzgerald\", \"pages\": 180, \"year\": 1925},\n",
    "    {\"title\": \"Tender Is the Night\", \"author\": \"F. Scott Fitzgerald\", \"pages\": 317, \"year\": 1934},\n",
    "    {\"title\": \"This Side of Paradise\", \"author\": \"F. Scott Fitzgerald\", \"pages\": 305, \"year\": 1920},\n",
    "    \n",
    "    {\"title\": \"Bartleby, the Scrivener\", \"author\": \"Herman Melville\", \"pages\": 64, \"year\": 1853},\n",
    "    {\"title\": \"Billy Budd, Sailor\", \"author\": \"Herman Melville\", \"pages\": 192, \"year\": 1924},\n",
    "]\n",
    "\n",
    "# Insert sample data\n",
    "collection.insert_many(sample_books)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MongoDB Aggregation\n",
    "\n",
    "#### Introduction\n",
    "MongoDB's aggregation framework is a powerful tool for performing data processing and analysis directly within the database. It allows you to transform and combine documents in a collection to produce aggregated results. PyMongo, the Python driver for MongoDB, provides a way to interact with MongoDB's aggregation framework.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Aggregation Pipeline\n",
    "The aggregation pipeline is a framework for data aggregation modeled on the concept of data processing pipelines. Documents enter a multi-stage pipeline that transforms the documents into aggregated results.\n",
    "\n",
    "![](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NOEORMhph8Nfu1F4patM3A.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax for an aggregation pipeline in MongoDB is a sequence of stages, where each stage transforms the documents as they pass through the pipeline. Each stage is represented as a document in an array, and the stages are processed in the order they appear.\n",
    "\n",
    "### General Syntax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    { <stage1>: { <stage-specific-operator1>: <expression1>, ... } },\n",
    "    { <stage2>: { <stage-specific-operator2>: <expression2>, ... } },\n",
    "    ...\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Common Stages\n",
    "1. **$match**: Filters documents.\n",
    "2. **$group**: Groups documents by a specified key.\n",
    "3. **$sort**: Sorts documents.\n",
    "4. **$project**: Reshapes documents by including, excluding, or adding fields.\n",
    "5. **$limit**: Limits the number of documents.\n",
    "6. **$skip**: Skips a specified number of documents.\n",
    "7. **$unwind**: Deconstructs an array field from the input documents to output a document for each element.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Example Pipeline\n",
    "Let's create an example pipeline that:\n",
    "1. Filters books with more than 150 pages.\n",
    "2. Groups the books by author and calculates the total number of pages for each author.\n",
    "3. Sorts the authors by the total number of pages in descending order.\n",
    "4. Projects the author and total pages fields, excluding the `_id` field.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'totalPages': 979, 'author': 'Jane Austen'}\n",
      "{'totalPages': 847, 'author': 'Harper Lee'}\n",
      "{'totalPages': 802, 'author': 'F. Scott Fitzgerald'}\n",
      "{'totalPages': 328, 'author': 'George Orwell'}\n",
      "{'totalPages': 192, 'author': 'Herman Melville'}\n"
     ]
    }
   ],
   "source": [
    "# Define each stage separately\n",
    "match_stage = {\n",
    "    \"$match\": {\n",
    "        \"pages\": { \"$gt\": 150 }\n",
    "    }\n",
    "}\n",
    "\n",
    "group_stage = {\n",
    "    \"$group\": {\n",
    "        \"_id\": \"$author\",\n",
    "        \"totalPages\": { \"$sum\": \"$pages\" }\n",
    "    }\n",
    "}\n",
    "\n",
    "sort_stage = {\n",
    "    \"$sort\": {\n",
    "        \"totalPages\": -1\n",
    "    }\n",
    "}\n",
    "\n",
    "project_stage = {\n",
    "    \"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"author\": \"$_id\",\n",
    "        \"totalPages\": 1\n",
    "    }\n",
    "}\n",
    "\n",
    "# Combine stages into a pipeline\n",
    "pipeline = [\n",
    "    match_stage,\n",
    "    group_stage,\n",
    "    sort_stage,\n",
    "    project_stage\n",
    "]\n",
    "\n",
    "# Execute the pipeline\n",
    "result = list(collection.aggregate(pipeline))\n",
    "for doc in result:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a table comparing SQL clauses (`SELECT`, `WHERE`, `GROUP BY`, `ORDER BY`) with their MongoDB aggregation framework equivalents.\n",
    "\n",
    "| **SQL Clause** | **MongoDB Aggregation Stage** | **Description** |\n",
    "|----------------|-------------------------------|-----------------|\n",
    "| `SELECT`       | `$project`                    | Specifies the fields to include or exclude in the output documents. |\n",
    "| `WHERE`        | `$match`                      | Filters the documents to pass only those that match the specified condition(s). |\n",
    "| `GROUP BY`     | `$group`                      | Groups input documents by a specified identifier expression and applies the accumulator expressions. |\n",
    "| `ORDER BY`     | `$sort`                       | Sorts all input documents and returns them in the specified order. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Explanation of MongoDB Stages\n",
    "- **$match**: Filters documents where `grades.score` is greater than 20.\n",
    "- **$group**: Groups documents by `cuisine` and calculates the average `grades.score` for each group.\n",
    "- **$sort**: Sorts the grouped documents by `averageScore` in descending order.\n",
    "- **$project**: Projects the `cuisine` and `averageScore` fields, excluding the `_id` field.\n",
    "\n",
    "This table and example illustrate how common SQL clauses map to MongoDB aggregation stages, helping to understand the similarities and differences between SQL and MongoDB queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "This pipeline demonstrates how to use multiple stages to filter, group, sort, and project documents in MongoDB using the aggregation framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Key Aggregation Operators\n",
    "1. **$match**\n",
    "2. **$group**\n",
    "3. **$sort**\n",
    "4. **$project**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. $match\n",
    "The `$match` stage filters documents to pass only the documents that match the specified condition(s) to the next pipeline stage.\n",
    "\n",
    "**Syntax:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"$match\": { <query> }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Example:**\n",
    "Filter books that have more than 250 pages.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, recall that we could use the `find()` function to filter the data, as shown in the previous lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('66eb9baaddbe7989b91b279a'), 'title': 'To Kill a Mockingbird', 'author': 'Harper Lee', 'pages': 281, 'year': 1960}\n",
      "{'_id': ObjectId('66eb9baaddbe7989b91b279b'), 'title': 'Go Set a Watchman', 'author': 'Harper Lee', 'pages': 278, 'year': 2015}\n",
      "{'_id': ObjectId('66eb9baaddbe7989b91b279c'), 'title': 'Mockingbird Songs: My Friendship with Harper Lee', 'author': 'Harper Lee', 'pages': 288, 'year': 2017}\n",
      "{'_id': ObjectId('66eb9baaddbe7989b91b279d'), 'title': '1984', 'author': 'George Orwell', 'pages': 328, 'year': 1949}\n",
      "{'_id': ObjectId('66eb9baaddbe7989b91b279f'), 'title': 'Pride and Prejudice', 'author': 'Jane Austen', 'pages': 279, 'year': 1813}\n",
      "{'_id': ObjectId('66eb9baaddbe7989b91b27a1'), 'title': 'Emma', 'author': 'Jane Austen', 'pages': 474, 'year': 1815}\n",
      "{'_id': ObjectId('66eb9baaddbe7989b91b27a3'), 'title': 'Tender Is the Night', 'author': 'F. Scott Fitzgerald', 'pages': 317, 'year': 1934}\n",
      "{'_id': ObjectId('66eb9baaddbe7989b91b27a4'), 'title': 'This Side of Paradise', 'author': 'F. Scott Fitzgerald', 'pages': 305, 'year': 1920}\n"
     ]
    }
   ],
   "source": [
    "for doc in collection.find({\"pages\": {\"$gt\": 250}}):\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use the `$match` method, to be used within an aggregation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('66eb9baaddbe7989b91b279a'), 'title': 'To Kill a Mockingbird', 'author': 'Harper Lee', 'pages': 281, 'year': 1960}\n",
      "{'_id': ObjectId('66eb9baaddbe7989b91b279b'), 'title': 'Go Set a Watchman', 'author': 'Harper Lee', 'pages': 278, 'year': 2015}\n",
      "{'_id': ObjectId('66eb9baaddbe7989b91b279c'), 'title': 'Mockingbird Songs: My Friendship with Harper Lee', 'author': 'Harper Lee', 'pages': 288, 'year': 2017}\n",
      "{'_id': ObjectId('66eb9baaddbe7989b91b279d'), 'title': '1984', 'author': 'George Orwell', 'pages': 328, 'year': 1949}\n",
      "{'_id': ObjectId('66eb9baaddbe7989b91b279f'), 'title': 'Pride and Prejudice', 'author': 'Jane Austen', 'pages': 279, 'year': 1813}\n",
      "{'_id': ObjectId('66eb9baaddbe7989b91b27a1'), 'title': 'Emma', 'author': 'Jane Austen', 'pages': 474, 'year': 1815}\n",
      "{'_id': ObjectId('66eb9baaddbe7989b91b27a3'), 'title': 'Tender Is the Night', 'author': 'F. Scott Fitzgerald', 'pages': 317, 'year': 1934}\n",
      "{'_id': ObjectId('66eb9baaddbe7989b91b27a4'), 'title': 'This Side of Paradise', 'author': 'F. Scott Fitzgerald', 'pages': 305, 'year': 1920}\n"
     ]
    }
   ],
   "source": [
    "pipeline = [\n",
    "    {\n",
    "        \"$match\": {\n",
    "            \"pages\": { \"$gt\": 250 }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "result = list(collection.aggregate(pipeline))\n",
    "for doc in result:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "The primary difference between `find` and `$match` in MongoDB lies in their usage and context within the MongoDB query language:\n",
    "\n",
    "**`find`**\n",
    "- **Context**: Used as a standalone query method.\n",
    "- **Purpose**: Retrieves documents from a collection that match the specified query criteria.\n",
    "- **Usage**: Directly used on a collection to fetch documents.\n",
    "- **Example**:\n",
    "  ```python\n",
    "  result = collection.find({\"pages\": {\"$gt\": 250}})\n",
    "  for doc in result:\n",
    "      print(doc)\n",
    "  \n",
    "\n",
    "**`$match`**\n",
    "- **Context**: Used within an aggregation pipeline.\n",
    "- **Purpose**: Filters documents to pass only those that match the specified condition(s) to the next stage in the pipeline.\n",
    "- **Usage**: Part of the aggregation framework, typically used in conjunction with other stages like `$group`, `$sort`, `$project`, etc.\n",
    "- **Example**:\n",
    "  ```python\n",
    "  pipeline = [\n",
    "      {\"$match\": {\"pages\": {\"$gt\": 250}}}\n",
    "  ]\n",
    "  result = collection.aggregate(pipeline)\n",
    "  for doc in result:\n",
    "      print(doc)\n",
    "  \n",
    "\n",
    "In summary, use `find` for straightforward document retrieval and `$match` within an aggregation pipeline for more complex data processing tasks.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. $group\n",
    "The `$group` stage groups input documents by the specified `_id` expression and for each distinct grouping, outputs a document. The output documents can also contain computed fields that hold the values of some accumulator expressions.\n",
    "\n",
    "**Syntax:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"$group\": {\n",
    "        \"_id\": <expression>,\n",
    "        <field1>: { <accumulator1> : <expression1> },\n",
    "        ...\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Explanation\n",
    "\n",
    "- **`$group`**: This is the stage operator that specifies the grouping operation.\n",
    "\n",
    "- **`_id`**: This field specifies the key by which to group the documents. The value of `_id` can be any valid expression that resolves to a value. Documents with the same `_id` value are grouped together. If you want to group all documents together, you can set `_id` to `null`.\n",
    "\n",
    "- **`<field1>`**: This is the name of the field in the output documents that will hold the result of the aggregation. You can specify multiple fields to perform different aggregations on the grouped data.\n",
    "\n",
    "- **`<accumulator1>`**: This specifies the accumulator operator to use for the aggregation. Common accumulator operators include:\n",
    "  - `$sum`: Calculates the sum of numeric values.\n",
    "  - `$avg`: Calculates the average of numeric values.\n",
    "  - `$min`: Finds the minimum value.\n",
    "  - `$max`: Finds the maximum value.\n",
    "  - `$push`: Appends values to an array.\n",
    "  - `$addToSet`: Adds values to an array, but only unique values.\n",
    "  - `$first`: Returns the first value in a group.\n",
    "  - `$last`: Returns the last value in a group.\n",
    "\n",
    "- **`<expression1>`**: This is the expression that specifies the field or value to be aggregated. It can be a field path, a constant value, or a more complex expression.\n",
    "\n",
    "### Example\n",
    "\n",
    "Let's consider an example where we group books by their author and calculate the total number of pages for each author.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 'Herman Melville', 'totalPages': 256}\n",
      "{'_id': 'George Orwell', 'totalPages': 440}\n",
      "{'_id': 'Jane Austen', 'totalPages': 979}\n",
      "{'_id': 'Harper Lee', 'totalPages': 847}\n",
      "{'_id': 'F. Scott Fitzgerald', 'totalPages': 802}\n"
     ]
    }
   ],
   "source": [
    "pipeline = [\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": \"$author\",  # Group by author\n",
    "            \"totalPages\": { \"$sum\": \"$pages\" }  # Calculate the sum of pages for each author\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "result = list(collection.aggregate(pipeline))\n",
    "for doc in result:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "In this example:\n",
    "- `_id`is set to `$author`, so the documents are grouped by the `author` field.\n",
    "- `totalPages` is the name of the field in the output documents.\n",
    "- `{ \"$sum\": \"$pages\" }` specifies that the `totalPages` field should contain the sum of the `pages` field for each group.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Example:**\n",
    " Group books by author to: \n",
    " - count the number of books for each author\n",
    " - determine the earliest publication year\n",
    " - determine the latest publication year.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 'Herman Melville', 'count': 2, 'min_year': 1853, 'max_year': 1924}\n",
      "{'_id': 'Harper Lee', 'count': 3, 'min_year': 1960, 'max_year': 2017}\n",
      "{'_id': 'F. Scott Fitzgerald', 'count': 3, 'min_year': 1920, 'max_year': 1934}\n",
      "{'_id': 'Jane Austen', 'count': 3, 'min_year': 1811, 'max_year': 1815}\n",
      "{'_id': 'George Orwell', 'count': 2, 'min_year': 1945, 'max_year': 1949}\n"
     ]
    }
   ],
   "source": [
    "pipeline = [\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": \"$author\",\n",
    "            \"count\": { \"$sum\": 1 },\n",
    "            \"min_year\": { \"$min\": \"$year\" },\n",
    "            \"max_year\": { \"$max\": \"$year\" }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "result = list(collection.aggregate(pipeline))\n",
    "for doc in result:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 3. $sort\n",
    "The `$sort` stage sorts all input documents and returns them to the pipeline in sorted order.\n",
    "\n",
    "**Syntax:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"$sort\": { <field1>: <sort order>, <field2>: <sort order>, ... }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Example:**\n",
    "Sort books by the number of pages in descending order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('66eb9baaddbe7989b91b27a1'), 'title': 'Emma', 'author': 'Jane Austen', 'pages': 474, 'year': 1815}\n",
      "{'_id': ObjectId('66eb9baaddbe7989b91b279d'), 'title': '1984', 'author': 'George Orwell', 'pages': 328, 'year': 1949}\n",
      "{'_id': ObjectId('66eb9baaddbe7989b91b27a3'), 'title': 'Tender Is the Night', 'author': 'F. Scott Fitzgerald', 'pages': 317, 'year': 1934}\n",
      "{'_id': ObjectId('66eb9baaddbe7989b91b27a4'), 'title': 'This Side of Paradise', 'author': 'F. Scott Fitzgerald', 'pages': 305, 'year': 1920}\n",
      "{'_id': ObjectId('66eb9baaddbe7989b91b279c'), 'title': 'Mockingbird Songs: My Friendship with Harper Lee', 'author': 'Harper Lee', 'pages': 288, 'year': 2017}\n",
      "{'_id': ObjectId('66eb9baaddbe7989b91b279a'), 'title': 'To Kill a Mockingbird', 'author': 'Harper Lee', 'pages': 281, 'year': 1960}\n",
      "{'_id': ObjectId('66eb9baaddbe7989b91b279f'), 'title': 'Pride and Prejudice', 'author': 'Jane Austen', 'pages': 279, 'year': 1813}\n",
      "{'_id': ObjectId('66eb9baaddbe7989b91b279b'), 'title': 'Go Set a Watchman', 'author': 'Harper Lee', 'pages': 278, 'year': 2015}\n",
      "{'_id': ObjectId('66eb9baaddbe7989b91b27a0'), 'title': 'Sense and Sensibility', 'author': 'Jane Austen', 'pages': 226, 'year': 1811}\n",
      "{'_id': ObjectId('66eb9baaddbe7989b91b27a6'), 'title': 'Billy Budd, Sailor', 'author': 'Herman Melville', 'pages': 192, 'year': 1924}\n",
      "{'_id': ObjectId('66eb9baaddbe7989b91b27a2'), 'title': 'The Great Gatsby', 'author': 'F. Scott Fitzgerald', 'pages': 180, 'year': 1925}\n",
      "{'_id': ObjectId('66eb9baaddbe7989b91b279e'), 'title': 'Animal Farm', 'author': 'George Orwell', 'pages': 112, 'year': 1945}\n",
      "{'_id': ObjectId('66eb9baaddbe7989b91b27a5'), 'title': 'Bartleby, the Scrivener', 'author': 'Herman Melville', 'pages': 64, 'year': 1853}\n"
     ]
    }
   ],
   "source": [
    "pipeline = [\n",
    "    {\n",
    "        \"$sort\": {\n",
    "            \"pages\": -1\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "result = list(collection.aggregate(pipeline))\n",
    "for doc in result:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 1: Sort by Author Name in Ascending Order**\n",
    "\n",
    "Sort the grouped results by author name in ascending order.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 'F. Scott Fitzgerald', 'count': 3, 'min_year': 1920, 'max_year': 1934}\n",
      "{'_id': 'George Orwell', 'count': 2, 'min_year': 1945, 'max_year': 1949}\n",
      "{'_id': 'Harper Lee', 'count': 3, 'min_year': 1960, 'max_year': 2017}\n",
      "{'_id': 'Herman Melville', 'count': 2, 'min_year': 1853, 'max_year': 1924}\n",
      "{'_id': 'Jane Austen', 'count': 3, 'min_year': 1811, 'max_year': 1815}\n"
     ]
    }
   ],
   "source": [
    "pipeline = [\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": \"$author\",\n",
    "            \"count\": { \"$sum\": 1 },\n",
    "            \"min_year\": { \"$min\": \"$year\" },\n",
    "            \"max_year\": { \"$max\": \"$year\" }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$sort\": {\n",
    "            \"_id\": 1  # Sort by author name in ascending order\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "result = list(collection.aggregate(pipeline))\n",
    "for doc in result:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 2: Sort by Count of Books in Descending Order**\n",
    "Sort the grouped results by the count of books in descending order.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 'Harper Lee', 'count': 3, 'min_year': 1960, 'max_year': 2017}\n",
      "{'_id': 'F. Scott Fitzgerald', 'count': 3, 'min_year': 1920, 'max_year': 1934}\n",
      "{'_id': 'Jane Austen', 'count': 3, 'min_year': 1811, 'max_year': 1815}\n",
      "{'_id': 'Herman Melville', 'count': 2, 'min_year': 1853, 'max_year': 1924}\n",
      "{'_id': 'George Orwell', 'count': 2, 'min_year': 1945, 'max_year': 1949}\n"
     ]
    }
   ],
   "source": [
    "pipeline = [\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": \"$author\",\n",
    "            \"count\": { \"$sum\": 1 },\n",
    "            \"min_year\": { \"$min\": \"$year\" },\n",
    "            \"max_year\": { \"$max\": \"$year\" }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$sort\": {\n",
    "            \"count\": -1  # Sort by count of books in descending order\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "result = list(collection.aggregate(pipeline))\n",
    "for doc in result:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 3: Sort by Count of Books in Descending Order and then by Author Name in Ascending Order**\n",
    "\n",
    "Sort the grouped results first by the count of books in descending order, and then by author name in ascending order.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 'F. Scott Fitzgerald', 'count': 3, 'min_year': 1920, 'max_year': 1934}\n",
      "{'_id': 'Harper Lee', 'count': 3, 'min_year': 1960, 'max_year': 2017}\n",
      "{'_id': 'Jane Austen', 'count': 3, 'min_year': 1811, 'max_year': 1815}\n",
      "{'_id': 'George Orwell', 'count': 2, 'min_year': 1945, 'max_year': 1949}\n",
      "{'_id': 'Herman Melville', 'count': 2, 'min_year': 1853, 'max_year': 1924}\n"
     ]
    }
   ],
   "source": [
    "pipeline = [\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": \"$author\",\n",
    "            \"count\": { \"$sum\": 1 },\n",
    "            \"min_year\": { \"$min\": \"$year\" },\n",
    "            \"max_year\": { \"$max\": \"$year\" }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$sort\": {\n",
    "            \"count\": -1,  # Sort by count of books in descending order\n",
    "            \"_id\": 1      # Then sort by author name in ascending order\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "result = list(collection.aggregate(pipeline))\n",
    "for doc in result:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. $project\n",
    "The `$project` stage reshapes each document in the stream, such as by adding new fields or removing existing fields.\n",
    "\n",
    "**Syntax:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"$project\": {\n",
    "        <field1>: <expression1>,\n",
    "        <field2>: <expression2>,\n",
    "        ...\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Example:**\n",
    "Project only the title and author fields of the books.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'To Kill a Mockingbird', 'author': 'Harper Lee'}\n",
      "{'title': 'Go Set a Watchman', 'author': 'Harper Lee'}\n",
      "{'title': 'Mockingbird Songs: My Friendship with Harper Lee', 'author': 'Harper Lee'}\n",
      "{'title': '1984', 'author': 'George Orwell'}\n",
      "{'title': 'Animal Farm', 'author': 'George Orwell'}\n",
      "{'title': 'Pride and Prejudice', 'author': 'Jane Austen'}\n",
      "{'title': 'Sense and Sensibility', 'author': 'Jane Austen'}\n",
      "{'title': 'Emma', 'author': 'Jane Austen'}\n",
      "{'title': 'The Great Gatsby', 'author': 'F. Scott Fitzgerald'}\n",
      "{'title': 'Tender Is the Night', 'author': 'F. Scott Fitzgerald'}\n",
      "{'title': 'This Side of Paradise', 'author': 'F. Scott Fitzgerald'}\n",
      "{'title': 'Bartleby, the Scrivener', 'author': 'Herman Melville'}\n",
      "{'title': 'Billy Budd, Sailor', 'author': 'Herman Melville'}\n"
     ]
    }
   ],
   "source": [
    "pipeline = [\n",
    "    {\n",
    "        \"$project\": {\n",
    "            \"title\": 1,\n",
    "            \"author\": 1,\n",
    "            \"_id\": 0\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "result = list(collection.aggregate(pipeline))\n",
    "for doc in result:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining stages into a pipeline\n",
    "\n",
    "You can combine multiple stages to form a more complex aggregation pipeline.\n",
    "\n",
    "**Example:**\n",
    "Find the top 2 authors with the most books, sorted by the number of books in descending order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 'Jane Austen', 'count': 3}\n",
      "{'_id': 'Harper Lee', 'count': 3}\n"
     ]
    }
   ],
   "source": [
    "pipeline = [\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": \"$author\",\n",
    "            \"count\": { \"$sum\": 1 }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$sort\": {\n",
    "            \"count\": -1\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$limit\": 2\n",
    "    }\n",
    "]\n",
    "\n",
    "result = list(collection.aggregate(pipeline))\n",
    "for doc in result:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's another example that combines multiple stages in an aggregation pipeline. This example will:\n",
    "\n",
    "1. Filter books published after the year 1900.\n",
    "2. Group the books by author and calculate the total number of pages and the average number of pages for each author.\n",
    "3. Sort the authors by the total number of pages in descending order.\n",
    "4. Project the author, total pages, and average pages fields, excluding the `_id` field.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'totalPages': 847, 'author': 'Harper Lee', 'averagePages': 282.33}\n",
      "{'totalPages': 802, 'author': 'F. Scott Fitzgerald', 'averagePages': 267.33}\n",
      "{'totalPages': 440, 'author': 'George Orwell', 'averagePages': 220.0}\n",
      "{'totalPages': 192, 'author': 'Herman Melville', 'averagePages': 192.0}\n"
     ]
    }
   ],
   "source": [
    "# Define each stage separately\n",
    "match_stage = {\n",
    "    \"$match\": {\n",
    "        \"year\": { \"$gt\": 1900 }\n",
    "    }\n",
    "}\n",
    "\n",
    "group_stage = {\n",
    "    \"$group\": {\n",
    "        \"_id\": \"$author\",\n",
    "        \"totalPages\": { \"$sum\": \"$pages\" },\n",
    "        \"averagePages\": { \"$avg\": \"$pages\" }\n",
    "    }\n",
    "}\n",
    "\n",
    "sort_stage = {\n",
    "    \"$sort\": {\n",
    "        \"totalPages\": -1\n",
    "    }\n",
    "}\n",
    "\n",
    "project_stage = {\n",
    "    \"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"author\": \"$_id\",\n",
    "        \"totalPages\": 1,\n",
    "        \"averagePages\": { \"$round\": [\"$averagePages\", 2] }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Combine stages into a pipeline\n",
    "pipeline = [\n",
    "    match_stage,\n",
    "    group_stage,\n",
    "    sort_stage,\n",
    "    project_stage\n",
    "]\n",
    "\n",
    "# Execute the pipeline\n",
    "result = list(collection.aggregate(pipeline))\n",
    "for doc in result:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Conclusion\n",
    "MongoDB's aggregation framework is a powerful tool for data analysis and transformation. By using stages like `$match`, `$group`, `$sort`, and `$project`, you can perform complex queries and data manipulations directly within the database. PyMongo provides a convenient way to interact with this framework from Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice exercises\n",
    "\n",
    "We are going to use the `restaurants` collection in the `sample_restaurants` database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = client.sample_restaurants\n",
    "collection = db.restaurants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a sample document in the `restaurants` collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('5eb3d668b31de5d588f4292c'),\n",
       " 'address': {'building': '2206',\n",
       "  'coord': [-74.1377286, 40.6119572],\n",
       "  'street': 'Victory Boulevard',\n",
       "  'zipcode': '10314'},\n",
       " 'borough': 'Staten Island',\n",
       " 'cuisine': 'Jewish/Kosher',\n",
       " 'grades': [{'date': datetime.datetime(2014, 10, 6, 0, 0),\n",
       "   'grade': 'A',\n",
       "   'score': 9},\n",
       "  {'date': datetime.datetime(2014, 5, 20, 0, 0), 'grade': 'A', 'score': 12},\n",
       "  {'date': datetime.datetime(2013, 4, 4, 0, 0), 'grade': 'A', 'score': 12},\n",
       "  {'date': datetime.datetime(2012, 1, 24, 0, 0), 'grade': 'A', 'score': 9}],\n",
       " 'name': 'Kosher Island',\n",
       " 'restaurant_id': '40356442'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.find_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Exercise 1: Count Restaurants by Borough\n",
    "**Objective**: Count the number of restaurants in each borough.\n",
    "\n",
    "1. **Group**: By borough.\n",
    "2. **Count**: The number of restaurants in each borough.\n",
    "3. **Sort**: By the count in descending order.\n",
    "4. **Project**: Borough and count.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'count': 10259, 'borough': 'Manhattan'}\n",
      "{'count': 6086, 'borough': 'Brooklyn'}\n",
      "{'count': 5656, 'borough': 'Queens'}\n",
      "{'count': 2338, 'borough': 'Bronx'}\n",
      "{'count': 969, 'borough': 'Staten Island'}\n",
      "{'count': 51, 'borough': 'Missing'}\n"
     ]
    }
   ],
   "source": [
    "group_stage = {\n",
    "    \"$group\": {\n",
    "        \"_id\": \"$borough\",\n",
    "        \"count\": { \"$sum\": 1 }\n",
    "    }\n",
    "}\n",
    "\n",
    "sort_stage = {\n",
    "    \"$sort\": {\n",
    "        \"count\": -1\n",
    "    }\n",
    "}\n",
    "\n",
    "project_stage = {\n",
    "    \"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"borough\": \"$_id\",\n",
    "        \"count\": 1\n",
    "    }\n",
    "}\n",
    "\n",
    "pipeline = [\n",
    "    group_stage,\n",
    "    sort_stage,\n",
    "    project_stage\n",
    "]\n",
    "\n",
    "result = list(collection.aggregate(pipeline))\n",
    "for doc in result:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Exercise 2: Find the Top 3 Cuisines with the Most Restaurants\n",
    "**Objective**: Identify the top 3 cuisines with the highest number of restaurants.\n",
    "\n",
    "1. **Group**: By cuisine.\n",
    "2. **Count**: The number of restaurants for each cuisine.\n",
    "3. **Sort**: By count in descending order.\n",
    "4. **Limit**: To the top 3 cuisines.\n",
    "5. **Project**: Cuisine and count.\n",
    "\n",
    "#### Example Code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'count': 6183, 'cuisine': 'American'}\n",
      "{'count': 2418, 'cuisine': 'Chinese'}\n",
      "{'count': 1214, 'cuisine': 'Caf√©/Coffee/Tea'}\n"
     ]
    }
   ],
   "source": [
    "# Define each stage separately\n",
    "group_stage = {\n",
    "    \"$group\": {\n",
    "        \"_id\": \"$cuisine\",\n",
    "        \"count\": { \"$sum\": 1 }\n",
    "    }\n",
    "}\n",
    "\n",
    "sort_stage = {\n",
    "    \"$sort\": {\n",
    "        \"count\": -1\n",
    "    }\n",
    "}\n",
    "\n",
    "limit_stage = {\n",
    "    \"$limit\": 3\n",
    "}\n",
    "\n",
    "project_stage = {\n",
    "    \"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"cuisine\": \"$_id\",\n",
    "        \"count\": 1\n",
    "    }\n",
    "}\n",
    "\n",
    "# Combine stages into a pipeline\n",
    "pipeline = [\n",
    "    group_stage,\n",
    "    sort_stage,\n",
    "    limit_stage,\n",
    "    project_stage\n",
    "]\n",
    "\n",
    "# Execute the pipeline\n",
    "result = list(collection.aggregate(pipeline))\n",
    "for doc in result:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Summary\n",
    "These exercises provide practice with the following stages:\n",
    "- **$group**: Grouping documents by a specified key and performing aggregations.\n",
    "- **$sort**: Sorting documents based on a specified field.\n",
    "- **$project**: Reshaping documents by including or excluding fields.\n",
    "- **$limit**: Limiting the number of documents passed to the next stage in the pipeline.\n",
    "\n",
    "By completing these exercises, students will gain hands-on experience with MongoDB's aggregation framework and learn how to perform complex data transformations and analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplemental materials\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read more here: https://www.mongodb.com/docs/manual/aggregation/\n",
    "\n",
    "MongoDB University lesson: https://learn.mongodb.com/learn/course/mongodb-aggregation-in-python/lesson-1-building-a-mongodb-aggregation-pipeline-in-python-applications/learn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
